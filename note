

 requests模块
 
response=requests.get(url="https://www.autohome.com.cn/news/")
print(response.status_code)
response.status.code
response.cookies
response.headers
response.content 字节类型 
response.text    字节类型转为了字符串类型
response.encoding="gbk"  解码

#标签对象：只要是标签对象就可以继续点操作下一级查找
obj = BeautifulSoup(response.text,'html.parser')
obj.find("div",attrs={'id':'xxx','class':'xx'})  # 从上到下找第一个div标签
还可以写成
obj.find(name="div",id="auto-channel-lazyload-article",_class="xx")  # 注意:_class
obj.find_all() # 返回标签对象列表，只找标签，recursive=True参数控制递归

obj.find("h3").text #取标签内容
xx=obj.find("img").attrs # 取img标签的所有属性
yy = obj.find("img").attrs.get("src") # 取src属性值
yy.name # 返回标签名
tag.attrs["id"] = 1  # 添加一个属性
del tag.attrs["id"]  # 删除一个属性



clear
decompose
extract() 有返回值，返回删除标签





src="//www3.autoimg.cn/newsdfs/g25/M04/4B/B8/120x90_0_autohomecar__wKgHIlpchUaADN4DAAILyRlNVFQ807.jpg"
v=src.rsplit('/',maxsplit=1)  # 右边第一个/分割
print(v[1])



# 高性能相关
多线程，多进程，线程池，进程池: 
python2没有线程池，有进程池
python3有线程池，也有进程池

# from  threading import Thread
from  concurrent.futures import ThreadPoolExecutor,ProcessPoolExecutor
pool = ThreadPoolExecutor(10)    # 最多创建10个线程,要求不高的情况下，线程池就可以了
#pool = ProcessPoolExecutor(10)  # 最多创建10个进程
def task(url):
   pass
   
url_list = [...]
for url in url_list:
   pool.submit(task,url)

异步IO性能更高: 
一个线程完成有IO的并发操作: 有很多模块实现 asyncio 
非阻塞： 不等待
异步： 回调
IO多路复用：
select: 检测socket对象是否发生变化（是否连接成功，是否有数据到来）

import socket
client = socket.socket()

client.connect(('ip',80))  # 创建连接
client.sendall(b"GET / HTTP/1.0 \r\nhost: www.baidu.com\r\n\r\n") # 发送HTTP请求
client.recv(8096) # 获取响应
print(data)
client.close() # 关闭连接






